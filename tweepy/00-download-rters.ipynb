{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweepy to sniff out Twitter bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load python tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import twint\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"yOr87HTwtpSFUKd1cn9lJBx7r\"\n",
    "consumer_secret=\"0B20b6fkTfScdUNRvEIRB9Mdx56GC7ojL6s4MJ2gbXpdgvKW62\"\n",
    "access_token=\"14790314-n8N9ncTt9jNG1G6wI7U7KxzaavRHg2U7fiDYE9m5Q\"\n",
    "access_token_secret=\"2egI4pF4tWaFQ3maNYV7poQKUD4NH19gHAhiMiAuPzlJV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = api.user_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter HashTag to search for\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " donotcomply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Date since The Tweets are required in yyyy-mm--dd\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2022-01-01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# number of tweets you want to extract in one run\u001b[39;00m\n\u001b[1;32m    112\u001b[0m numtweet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 113\u001b[0m \u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_since\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumtweet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping has completed!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mscrape\u001b[0;34m(words, date_since, numtweet)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;66;03m# Here we are appending all the\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;66;03m# extracted information in the DataFrame\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         ith_tweet \u001b[38;5;241m=\u001b[39m [username, description,\n\u001b[1;32m     78\u001b[0m                      location, following,\n\u001b[1;32m     79\u001b[0m                      followers, totaltweets,\n\u001b[1;32m     80\u001b[0m                      retweetcount, text, hashtext]\n\u001b[0;32m---> 81\u001b[0m         db\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(db)] \u001b[38;5;241m=\u001b[39m ith_tweet\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;66;03m# Function call to print tweet data on screen\u001b[39;00m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# printtweetdata(i, ith_tweet)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# i = i+1\u001b[39;00m\n\u001b[1;32m     86\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraped_tweets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/notebooks-sxqKeO4C/lib/python3.8/site-packages/pandas/core/indexing.py:723\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    722\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 723\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/notebooks-sxqKeO4C/lib/python3.8/site-packages/pandas/core/indexing.py:1724\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1721\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 1724\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/notebooks-sxqKeO4C/lib/python3.8/site-packages/pandas/core/indexing.py:2027\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 2027\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2029\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mappend(value)\u001b[38;5;241m.\u001b[39m_mgr\n",
      "\u001b[0;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "        print()\n",
    "        print(f\"Tweet {n}:\")\n",
    "        print(f\"Username:{ith_tweet[0]}\")\n",
    "        print(f\"Description:{ith_tweet[1]}\")\n",
    "        print(f\"Location:{ith_tweet[2]}\")\n",
    "        print(f\"Following Count:{ith_tweet[3]}\")\n",
    "        print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "        print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "        print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "        print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "        print(f\"Hashtags Used:{ith_tweet[8]}\")\n",
    " \n",
    " \n",
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    " \n",
    "        # Creating DataFrame using pandas\n",
    "        db = pd.DataFrame(columns=['datetime_utc',\n",
    "                                   'username',\n",
    "                                   'description',\n",
    "                                   'location',\n",
    "                                   'following',\n",
    "                                   'followers',\n",
    "                                   'totaltweets',\n",
    "                                   'retweetcount',\n",
    "                                   'text',\n",
    "                                   'hashtags'])\n",
    " \n",
    "        # We are using .Cursor() to search\n",
    "        # through twitter for the required tweets.\n",
    "        # The number of tweets can be\n",
    "        # restricted using .items(number of tweets)\n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                               words, lang=\"en\",\n",
    "                               since_id=date_since,\n",
    "                               tweet_mode='extended').items(numtweet)\n",
    " \n",
    " \n",
    "        # .Cursor() returns an iterable object. Each item in\n",
    "        # the iterator has various attributes\n",
    "        # that you can access to\n",
    "        # get information about each tweet\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    " \n",
    "        # Counter to maintain Tweet Count\n",
    "        i = 1\n",
    " \n",
    "        # we will iterate over each tweet in the\n",
    "        # list for extracting information about each tweet\n",
    "        for tweet in list_tweets:\n",
    "                datetime_utc = tweet.user.created_at\n",
    "                username = tweet.user.screen_name\n",
    "                description = tweet.user.description\n",
    "                location = tweet.user.location\n",
    "                following = tweet.user.friends_count\n",
    "                followers = tweet.user.followers_count\n",
    "                totaltweets = tweet.user.statuses_count\n",
    "                retweetcount = tweet.retweet_count\n",
    "                hashtags = tweet.entities['hashtags']\n",
    " \n",
    "                # Retweets can be distinguished by\n",
    "                # a retweeted_status attribute,\n",
    "                # in case it is an invalid reference,\n",
    "                # except block will be executed\n",
    "                try:\n",
    "                        text = tweet.retweeted_status.full_text\n",
    "                except AttributeError:\n",
    "                        text = tweet.full_text\n",
    "                hashtext = list()\n",
    "                for j in range(0, len(hashtags)):\n",
    "                        hashtext.append(hashtags[j]['text'])\n",
    " \n",
    "                # Here we are appending all the\n",
    "                # extracted information in the DataFrame\n",
    "                ith_tweet = [username, description,\n",
    "                             location, following,\n",
    "                             followers, totaltweets,\n",
    "                             retweetcount, text, hashtext]\n",
    "                db.loc[len(db)] = ith_tweet\n",
    " \n",
    "                # Function call to print tweet data on screen\n",
    "                # printtweetdata(i, ith_tweet)\n",
    "                # i = i+1\n",
    "        filename = 'scraped_tweets.csv'\n",
    " \n",
    "        # we will save our database as a CSV file.\n",
    "        db.to_csv(filename)\n",
    " \n",
    "if __name__ == '__main__':\n",
    " \n",
    "        # Enter your own credentials obtained\n",
    "        # from your developer account       \n",
    "        consumer_key=\"yOr87HTwtpSFUKd1cn9lJBx7r\"\n",
    "        consumer_secret=\"0B20b6fkTfScdUNRvEIRB9Mdx56GC7ojL6s4MJ2gbXpdgvKW62\"\n",
    "        access_key=\"14790314-n8N9ncTt9jNG1G6wI7U7KxzaavRHg2U7fiDYE9m5Q\"\n",
    "        access_secret=\"2egI4pF4tWaFQ3maNYV7poQKUD4NH19gHAhiMiAuPzlJV\"\n",
    " \n",
    " \n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    " \n",
    "        # Enter Hashtag and initial date\n",
    "        print(\"Enter Twitter HashTag to search for\")\n",
    "        words = input()\n",
    "        print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "        date_since = input()\n",
    " \n",
    "        # number of tweets you want to extract in one run\n",
    "        numtweet = 1000\n",
    "        scrape(words, date_since, numtweet)\n",
    "        print('Scraping has completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
